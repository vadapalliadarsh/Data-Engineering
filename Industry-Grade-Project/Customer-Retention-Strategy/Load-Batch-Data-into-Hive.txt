
+++++++++++++ Data cleansing +++++++++++++
/// move data from main directory to our drectory to avoid loss of data in main directory ///

hdfs dfs -mkdir industry_grade_project
hdfs dfs -cp /bigdatapgp/common_folder/project_futurecart/batchdata/* industry_grade_project/



/// remover header from file to avoid header being loaded in the tables in the later stage ///
/// creating shell script for the above task ///

vi remover_header.sh

mkdir industry_grade_project
hdfs dfs -copyToLocal industry_grade_project/futurecart_case_survey_details.txt industry_grade_project/
sed '1d' industry_grade_project/futurecart_case_survey_details.txt > industry_grade_project/Cfuturecart_case_survey_details.txt
hdfs dfs -rm industry_grade_project/futurecart_case_survey_details.txt
hdfs dfs -put industry_grade_project/Cfuturecart_case_survey_details.txt industry_grade_project/futurecart_case_survey_details.txt

hdfs dfs -copyToLocal industry_grade_project/futurecart_case_details.txt industry_grade_project/
sed '1d' industry_grade_project/futurecart_case_details.txt > industry_grade_project/Cfuturecart_case_details.txt
hdfs dfs -rm industry_grade_project/futurecart_case_details.txt
hdfs dfs -put industry_grade_project/Cfuturecart_case_details.txt industry_grade_project/futurecart_case_details.txt

sh remover_header.sh




+++++++++++++ Loading cleansed Data into MySQl +++++++++++++
/// creating edureka_653389_futurecart_case_details table in MySQl ///

sqoop eval --connect jdbc:mysql://dbserver.edu.cloudlab.com/labuser_database \
--query "create table edureka_653389_futurecart_case_details( \
case_no varchar(50), \
create_timestamp varchar(50), \
last_modified_timestamp varchar(50), \
created_employee_key varchar(50), \
call_center_id varchar(50), \
status varchar(50), \
category varchar(50), \
sub_category varchar(50), \
communication_mode varchar(50), \
country_cd varchar(50), \
product_code varchar(50))" \
--username edu_labuser \
--password edureka



/// creating edureka_653389_futurecart_case_survey_details table in MySQl ///

sqoop eval --connect jdbc:mysql://dbserver.edu.cloudlab.com/labuser_database \
--query "create table edureka_653389_futurecart_case_survey_details( \
survey_id varchar(50), \
case_no varchar(50), \
survey_timestamp varchar(50), \
q1 varchar(50), \
q2 varchar(50), \
q3 varchar(50), \
q4 varchar(50), \
q5 varchar(50))" \
--username edu_labuser \
--password edureka



/// loading data into edureka_653389_futurecart_case_details table in MySQl ///

sqoop export --connect jdbc:mysql://dbserver.edu.cloudlab.com/labuser_database \
--username edu_labuser \
--password edureka \
--table edureka_653389_futurecart_case_details \
--input-fields-terminated-by '\t' \
--export-dir /user/edureka_653389/industry_grade_project/futurecart_case_details.txt \
-m 1



/// loading data into edureka_653389_futurecart_case_survey_details table in MySQl ///

sqoop export --connect jdbc:mysql://dbserver.edu.cloudlab.com/labuser_database \
--username edu_labuser \
--password edureka \
--table edureka_653389_futurecart_case_survey_details \
--input-fields-terminated-by '\t' \
--export-dir /user/edureka_653389/industry_grade_project/futurecart_case_survey_details.txt \
-m 1




+++++++++++++ Loading Data into HIVE from MySQl +++++++++++++
/// futurecart_case_details ///
/// create table stg table ///
create table edureka_653389.futurecart_case_details_stg( case_no varchar(50), create_timestamp varchar(50), last_modified_timestamp varchar(50), created_employee_key varchar(50), call_center_id varchar(50), status varchar(50), category varchar(50), sub_category varchar(50), communication_mode varchar(50), country_cd varchar(50), product_code varchar(50)) row format delimited fields terminated by ',';



/// import data into stg hive table from MySQl ///

sqoop import --connect "jdbc:mysql://dbserver.edu.cloudlab.com/labuser_database" \
--username edu_labuser \
--password  "edureka" \
--query "select * from edureka_653389_futurecart_case_details where \$CONDITIONS" \
--target-dir /tmp/edureka_719925/edureka_653389_futurecart_case_details \
--delete-target-dir \
--split-by create_timestamp \
--hive-import \
--hive-overwrite \
--hive-database edureka_653389 \
--hive-table futurecart_case_details_stg \
--hive-drop-import-delims \
--fields-terminated-by ',' \
--m 10



/// creating and inserting data into temp table by adding row_insertion_dttm and create_date ///

CREATE TABLE IF NOT EXISTS edureka_653389.futurecart_case_details_temp STORED AS ORC AS SELECT stg.*, current_timestamp() as row_insertion_dttm, split(stg.create_timestamp, " ")[0] as create_date from edureka_653389.futurecart_case_details_stg stg;



/// create final table with partition ///

create table edureka_653389.futurecart_case_details (case_no varchar(50), create_timestamp varchar(50), last_modified_timestamp varchar(50), created_employee_key varchar(50), call_center_id varchar(50), status varchar(50), category varchar(50), sub_category varchar(50), communication_mode varchar(50), country_cd varchar(50), product_code varchar(50), row_insertion_dttm varchar(50)) partitioned by (create_date date) STORED AS ORC;


set hive.exec.dynamic.partition.mode=nonstrict;


//// insert data into final table ///

insert overwrite table edureka_653389.futurecart_case_details partition (create_date) select case_no, create_timestamp, last_modified_timestamp, created_employee_key, call_center_id, status, category, sub_category, communication_mode, country_cd, product_code, row_insertion_dttm, create_date from edureka_653389.futurecart_case_details_temp;




/// futurecart_case_survey_details ///
/// create table stg table ///
create table edureka_653389.futurecart_case_survey_details_stg( survey_id varchar(50), case_no varchar(50), survey_timestamp varchar(50), q1 varchar(50), q2 varchar(50), q3 varchar(50), q4 varchar(50), q5 varchar(50)) row format delimited fields terminated by ',';



/// import data into stg hive table from MySQl ///

sqoop import --connect "jdbc:mysql://dbserver.edu.cloudlab.com/labuser_database" \
--username edu_labuser \
--password  "edureka" \
--query "select * from edureka_653389_futurecart_case_survey_details where \$CONDITIONS" \
--target-dir /tmp/edureka_719925/edureka_653389_futurecart_case_survey_details \
--delete-target-dir \
--split-by survey_timestamp \
--hive-import \
--hive-overwrite \
--hive-database edureka_653389 \
--hive-table futurecart_case_survey_details_stg \
--hive-drop-import-delims \
--fields-terminated-by ',' \
--m 10



/// creating and inserting data into temp table by adding row_insertion_dttm and survey_date ///

CREATE TABLE IF NOT EXISTS edureka_653389.futurecart_case_survey_details_temp STORED AS ORC AS SELECT stg.*, current_timestamp() as row_insertion_dttm, split(stg.survey_timestamp, " ")[0] as survey_date from edureka_653389.futurecart_case_survey_details_stg stg;



/// create final table with partition ///

create table edureka_653389.futurecart_case_survey_details (survey_id varchar(50), case_no varchar(50), survey_timestamp varchar(50), q1 varchar(50), q2 varchar(50), q3 varchar(50), q4 varchar(50), q5 varchar(50), row_insertion_dttm varchar(50)) partitioned by (survey_date date) STORED AS ORC;


set hive.exec.dynamic.partition.mode=nonstrict;


//// insert data into final table ///

insert overwrite table edureka_653389.futurecart_case_survey_details partition (survey_date) select survey_id, case_no, survey_timestamp, q1, q2, q3, q4, q5, row_insertion_dttm, survey_date from edureka_653389.futurecart_case_survey_details_temp;


